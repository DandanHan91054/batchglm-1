{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from batchglm.unit_test.test_jacobians_glm_all_tf2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def _ll(eta_loc, eta_scale, loc, scale, x, n_features):\n",
    "\n",
    "        # Log-likelihood:\n",
    "        log_r_plus_mu = tf.math.log(scale + loc)\n",
    "        if isinstance(x, tf.SparseTensor):\n",
    "            log_probs_sparse = x.__mul__(eta_loc - log_r_plus_mu)\n",
    "            log_probs_dense = tf.math.lgamma(tf.sparse.add(x, scale)) - \\\n",
    "                              tf.math.lgamma(tf.sparse.add(x, tf.ones(shape=x.dense_shape, dtype=self.ll_dtype))) - \\\n",
    "                              tf.math.lgamma(scale) + \\\n",
    "                              tf.multiply(scale, eta_scale - log_r_plus_mu)\n",
    "            log_probs = tf.sparse.add(log_probs_sparse, log_probs_dense)\n",
    "            # log_probs.set_shape([None, n_features])  # need as shape completely lost.\n",
    "        else:\n",
    "            # print(scale.get_shape())\n",
    "            # print(x.get_shape())\n",
    "            log_probs = tf.math.lgamma(scale + x) - \\\n",
    "                        tf.math.lgamma(x + tf.ones_like(x)) - \\\n",
    "                        tf.math.lgamma(scale) + \\\n",
    "                        tf.multiply(x, eta_loc - log_r_plus_mu) + \\\n",
    "                        tf.multiply(scale, eta_scale - log_r_plus_mu)\n",
    "\n",
    "        # log_probs = self.tf_clip_param(log_probs, \"log_probs\")\n",
    "        return log_probs\n",
    "def analytic():\n",
    "    x_minus_loc = tf.subtract(x,loc)\n",
    "    scalar_one = tf.constant(1, shape=(), dtype=tf.dtypes.float64)\n",
    "    a_model = tf.divide(tf.multiply(scale, x_minus_loc), tf.add(loc, scale))\n",
    "    print(\"a_model: \", a_model)\n",
    "    r_plus_mu = scale + loc\n",
    "    scale_plus_x = scale + x\n",
    "    # Define graphs for individual terms of constant term of hessian:\n",
    "    const1 = tf.subtract(\n",
    "        tf.math.digamma(x=scale_plus_x),\n",
    "        tf.math.digamma(x=scale)\n",
    "    )\n",
    "    const2 = tf.negative(scale_plus_x / r_plus_mu)\n",
    "    const3 = tf.add(\n",
    "        tf.math.log(scale),\n",
    "        scalar_one - tf.math.log(r_plus_mu)\n",
    "    )\n",
    "    #const = const1 + const2\n",
    "    #const +=const3\n",
    "    const = tf.add_n([const1, const2, const3])  # [observations, features]\n",
    "    b_model = scale * const\n",
    "    a_model = tf.matmul(tf.transpose(a_model), design_loc)\n",
    "    b_model = tf.matmul(tf.transpose(b_model), design_scale)\n",
    "    print(x.dtype)\n",
    "    print(loc.dtype)\n",
    "    print(scale.dtype)\n",
    "    print(x_minus_loc.dtype)\n",
    "    return tf.concat([a_model, b_model], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E0915 12:43:39.468703 140048598378304 test_jacobians_glm_all_tf2.py:156] Test_Jacobians_GLM_NB.test_compute_jacobians_nb()\n",
      "E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ja ich habe den mist initialisiert\n",
      "float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ERROR: test_compute_jacobians_nb (batchglm.unit_test.test_jacobians_glm_all_tf2.Test_Jacobians_GLM_NB)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mario/PSC19/batchglm_tf2/batchglm/unit_test/test_jacobians_glm_all_tf2.py\", line 159, in test_compute_jacobians_nb\n",
      "    self._test_compute_jacobians(sparse=False)\n",
      "  File \"/home/mario/PSC19/batchglm_tf2/batchglm/unit_test/test_jacobians_glm_all_tf2.py\", line 148, in _test_compute_jacobians\n",
      "    self.compare_jacs(design=\"~ 1 + condition + batch\", sparse=sparse)\n",
      "  File \"/home/mario/PSC19/batchglm_tf2/batchglm/unit_test/test_jacobians_glm_all_tf2.py\", line 118, in compare_jacs\n",
      "    J_analytic = self.get_jacs(input_data)\n",
      "  File \"/home/mario/PSC19/batchglm_tf2/batchglm/unit_test/test_jacobians_glm_all_tf2.py\", line 74, in get_jacs\n",
      "    \"autograd\": pkg_constants.JACOBIAN_MODE == \"tf\"\n",
      "  File \"/home/mario/PSC19/batchglm_tf2/batchglm/train/tf2/base_glm/estimator.py\", line 63, in train_sequence\n",
      "    autograd=trainingStrategy['autograd'] if 'autograd' in trainingStrategy else False\n",
      "  File \"/home/mario/PSC19/batchglm_tf2/batchglm/train/tf2/glm_nb/estimator.py\", line 117, in train\n",
      "    autograd=autograd\n",
      "  File \"/home/mario/PSC19/batchglm_tf2/batchglm/train/tf2/base_glm/estimator.py\", line 90, in _train\n",
      "    input_list = data.map(self.fetch_fn, num_parallel_calls=pkg_constants.TF_NUM_THREADS)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1146, in map\n",
      "    self, map_func, num_parallel_calls, preserve_cardinality=True)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3264, in __init__\n",
      "    use_legacy_function=use_legacy_function)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2591, in __init__\n",
      "    self._function = wrapper_fn._get_concrete_function_internal()\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1366, in _get_concrete_function_internal\n",
      "    *args, **kwargs)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1360, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1648, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1541, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 716, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2585, in wrapper_fn\n",
      "    ret = _wrapper_helper(*args)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2530, in _wrapper_helper\n",
      "    ret = func(*nested_args)\n",
      "  File \"/home/mario/PSC19/batchglm_tf2/batchglm/train/tf2/base_glm/estimator.py\", line 349, in fetch_fn\n",
      "    x_tensor.set_shape([idx.get_shape().as_list()] + [self._input_data.num_features])\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 564, in set_shape\n",
      "    shape = tensor_shape.TensorShape(shape)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 781, in __init__\n",
      "    self._dims = [as_dimension(d) for d in dims_iter]\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 781, in <listcomp>\n",
      "    self._dims = [as_dimension(d) for d in dims_iter]\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 723, in as_dimension\n",
      "    return Dimension(value)\n",
      "  File \"/home/mario/miniconda3/envs/batchglm_tf2/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 192, in __init__\n",
      "    self._value = int(value)\n",
      "TypeError: int() argument must be a string, a bytes-like object or a number, not 'list'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.076s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f5f94459a20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['first-arg-is-ignored'], exit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 287.,  300.],\n",
       "       [1331., 1200.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[287,300],[1331,1200]], dtype=\"float64\")\n",
    "print(type(x))\n",
    "np.ndarray(shape=(2,2),buffer=x, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 0.]], shape=(2, 2), dtype=float64)\n",
      "<tf.Variable 'Variable:0' shape=(4, 2) dtype=float64, numpy=\n",
      "array([[7.15805998, 7.34018684],\n",
      "       [0.        , 0.        ],\n",
      "       [2.17102654, 0.43241663],\n",
      "       [0.        , 0.        ]])>\n",
      "tf.Tensor(\n",
      "[[-1.72992901e+00  1.44090677e-08]\n",
      " [ 2.39602649e+00  1.24074074e+00]\n",
      " [ 1.35365258e-01  5.08817847e-01]\n",
      " [-1.02071679e-01  7.30115644e-01]], shape=(4, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a_var = tf.constant([[7.15805998, 7.34018684],[0,0]], dtype=tf.dtypes.float64)\n",
    "b_var = tf.constant([[2.17102654, 0.43241663],[0,0]], dtype=tf.dtypes.float64)\n",
    "params = tf.concat([a_var,b_var], axis=0)\n",
    "params = tf.Variable(params)\n",
    "design_loc = tf.constant([[1,1],[1,0]], dtype=tf.dtypes.float64) #n_obs x coeff\n",
    "design_scale = tf.constant([[1,1],[1,0]], dtype=tf.dtypes.float64)\n",
    "x = tf.constant([[931.,299.],[1893.,2783.]], dtype=tf.dtypes.float64) # n_obs x features\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(params)\n",
    "    a_var = params[0:2]\n",
    "    b_var = params[2:4]\n",
    "    print(design_loc)\n",
    "    print(params)\n",
    "    eta_loc = tf.matmul(design_loc, a_var)\n",
    "    eta_scale = tf.matmul(design_scale, b_var)\n",
    "    loc = tf.exp(eta_loc)\n",
    "    scale= tf.exp(eta_scale)\n",
    "    result = _ll(eta_loc,eta_scale,loc,scale, x, 3)\n",
    "xxx = g.gradient(result, params)\n",
    "\n",
    "\n",
    "print(tf.negative(xxx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_model:  tf.Tensor(\n",
      "[[-2.39602649 -1.24074074]\n",
      " [ 4.12595551  1.24074073]], shape=(2, 2), dtype=float64)\n",
      "<dtype: 'float64'>\n",
      "<dtype: 'float64'>\n",
      "<dtype: 'float64'>\n",
      "<dtype: 'float64'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=184, shape=(4, 2), dtype=float64, numpy=\n",
       "array([[-1.72992901e+00,  1.44087806e-08],\n",
       "       [ 2.39602649e+00,  1.24074074e+00],\n",
       "       [ 1.35365258e-01,  5.08817847e-01],\n",
       "       [-1.02071679e-01,  7.30115644e-01]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.negative(tf.transpose(analytic()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-8c801b035616>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-8c801b035616>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    [ 2.96656217  1.24074074]], shape=(2, 2), dtype=float64)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a_model:  tf.Tensor(\n",
    "[[-2.96656217 -1.24074074]\n",
    " [ 2.96656217  1.24074074]], shape=(2, 2), dtype=float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
